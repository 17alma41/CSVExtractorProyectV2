# CSVExtractorProyect V2

**CSVExtractorProyect V2** es una soluci√≥n profesional y automatizada para la extracci√≥n, filtrado y enmascarado de datos de contacto (emails, redes sociales, tel√©fonos, etc.) desde archivos CSV y p√°ginas web. El sistema est√° dise√±ado para ser robusto, modular y f√°cil de usar, permitiendo reanudar procesos y controlar errores de forma inteligente.

---

## üöÄ ¬øQu√© hace este proyecto?
- **Limpia y normaliza** archivos CSV de entrada.
- **Extrae** emails y redes sociales de sitios web usando scraping avanzado y paralelismo autom√°tico.
- **Filtra** emails no deseados seg√∫n listas de exclusi√≥n configurables.
- **Genera archivos demo** enmascarados/an√≥nimos para compartir sin exponer datos reales.
- **Registra el estado** de cada archivo y etapa, permitiendo reanudar procesos interrumpidos.
- **Gestiona errores** y logs de forma centralizada y profesional.

---

## üìÅ Estructura del proyecto

```
CSVExtractorProyectV2/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Punto de entrada CLI
‚îÇ   ‚îú‚îÄ‚îÄ settings.py            # Configuraci√≥n de rutas y constantes
‚îÇ   ‚îú‚îÄ‚îÄ extractor/             # Extracci√≥n y limpieza
‚îÇ   ‚îú‚îÄ‚îÄ cleaner/               # Filtrado de exclusiones
‚îÇ   ‚îú‚îÄ‚îÄ demo/                  # Generaci√≥n de archivos demo
‚îÇ   ‚îú‚îÄ‚îÄ utils/                 # Utilidades y gesti√≥n de estado/logs
‚îú‚îÄ‚îÄ config/                    # Configuraci√≥n de columnas y exclusiones
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ inputs/                # CSV originales
‚îÇ   ‚îú‚îÄ‚îÄ clean_inputs/          # CSV normalizados
‚îÇ   ‚îú‚îÄ‚îÄ outputs/               # Resultados del scraping
‚îÇ   ‚îú‚îÄ‚îÄ exclusions_outputs/    # Resultados tras exclusi√≥n
‚îÇ   ‚îî‚îÄ‚îÄ demo_outputs/          # Archivos demo enmascarados
‚îú‚îÄ‚îÄ logs/                      # Logs y estado de ejecuci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ procesamiento.log
‚îÇ   ‚îú‚îÄ‚îÄ status.json
‚îÇ   ‚îî‚îÄ‚îÄ error_log.txt
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias Python
‚îî‚îÄ‚îÄ README.md                  # Esta documentaci√≥n
```

---

## ‚öôÔ∏è Instalaci√≥n

1. **Clona el repositorio** y entra en la carpeta del proyecto.
2. Instala las dependencias:
   ```powershell
   pip install -r requirements.txt
   ```
   > **Nota:** Aseg√∫rate de tener tambi√©n `matplotlib` y `Pillow` (se instalan autom√°ticamente con el comando anterior).
3. Aseg√∫rate de tener el driver de Selenium (ej: `chromedriver.exe`) en la carpeta `/drivers`.

---
## ‚ñ∂Ô∏è Instrucciones de uso

1. Agrega los archivos ``.csv`` a la carpeta ``data/inputs``
2. Ejecuta el script principal:
  ```bash
    python src/main.py --all
  ```
4. Seguira el flujo completo ``extracci√≥n -> filtrado -> demos``
5. Cada resultado se ir√° almacenando en su carpeta correspondiente `data/clean_inputs -> data/outputs -> data/exclusions_outputs -> data/demo_outputs`



---

## üñ•Ô∏è Uso r√°pido

### Flujo completo automatizado

```powershell
python src/main.py --all
```

### Opciones principales
- `--all`           Ejecuta todo el flujo: limpieza ‚Üí scraping ‚Üí exclusi√≥n ‚Üí demo
- `--extract`       Solo extracci√≥n web
- `--filter`        Solo filtrado de exclusiones
- `--demo`          Solo generaci√≥n de demo
- `--overwrite`     Fuerza reprocesado de archivos ya procesados
- `--test`          Procesa solo 20 filas por archivo (modo prueba)
- `--wait-timeout`  Timeout de espera por p√°gina (segundos)
- `--resume`        Reanuda archivos/URLs incompletos o fallidos
- `--clean-logs`    Limpia todos los archivos de la carpeta logs (requiere confirmaci√≥n)

### Ejemplo de uso avanzado
```powershell
python src/main.py --all --overwrite --test --wait-timeout 15
```

---


## üìù Sacar informaci√≥n para FicherosDatos

Este script recorre carpetas por pa√≠s dentro de una ruta en red, localiza archivos Excel, extrae m√©tricas
espec√≠ficas desde la hoja "statistics" de cada archivo, asocia hasta tres im√°genes JPG disponibles, y genera un
archivo resumen en Excel con toda esa informaci√≥n.

- Ejecutalo para aplicar este codigo y obtener los datos en un excel
```bash
  python src/scripts/ficheros_datos.py
```
- Obtendras los resultados en `data/outputs` para poder observarlo.

---

## üß† Caracter√≠sticas avanzadas

- **Reanudaci√≥n inteligente:** Si el proceso se interrumpe, puedes reanudar exactamente donde qued√≥ con `--resume`.
- **Control de estado:** El progreso de cada archivo y etapa se guarda en `/logs/status.json`.
- **Logs de errores:** Todos los errores se registran en `/logs/error_log.txt` con detalles.
- **Paralelismo autom√°tico:** El sistema ajusta el n√∫mero de hilos seg√∫n tu hardware.
- **Configuraci√≥n flexible:** Puedes personalizar columnas, exclusiones y orden en `/config/txt_config/`.

---

## üìù Personalizaci√≥n y configuraci√≥n
- Edita los archivos en `/config/txt_config/` para:
  - Eliminar columnas innecesarias
  - Renombrar columnas
  - Definir el orden de columnas
  - Configurar listas de exclusi√≥n de emails

---

## üõ†Ô∏è Estructura de los m√≥dulos principales

- **src/main.py**: CLI principal y orquestador del flujo.
- **src/extractor/**: Extracci√≥n web, limpieza y generaci√≥n de Excel.
- **src/cleaner/**: Filtrado de emails por exclusi√≥n.
- **src/demo/**: Enmascarado/an√≥nimo para archivos demo.
- **src/utils/status_manager.py**: Manejo de estado y logs para reanudaci√≥n y control de errores.

---

## ‚ùì Preguntas frecuentes

- **¬øPuedo reanudar si se corta la luz o hay un error?**
  S√≠, ejecuta el mismo comando con `--resume` y el sistema continuar√° donde se detuvo.
- **¬øC√≥mo limpio los logs y el estado para empezar de cero?**
  Ejecuta: `python src/main.py --clean-logs`
- **¬øPuedo personalizar el scraping?**
  S√≠, ajusta los par√°metros por CLI o edita la configuraci√≥n en `/config/txt_config/`.

---

## üìÑ Licencia
Este proyecto es privado y su uso est√° restringido a los t√©rminos acordados por el propietario.

---







